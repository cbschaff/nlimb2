import envs
import utils
import rl
import nlimb
import tasks

logging.wandb_init.project = 'isaac_gym'
logging.wandb_init.entity = 'chipschaff'

rl.train.logdir = '/exps/nlimb'
rl.train.algorithm = @nlimb.NLIMB
rl.train.maxt = 1000000000
rl.train.seed = 0
rl.train.eval = True
rl.train.eval_period = 1000000000
rl.train.save_period = 50000000
rl.train.maxseconds = None
rl.train.make_logdir_unique = True

nlimb.NLIMB.env = @envs.IsaacMixedXMLEnv
nlimb.NLIMB.rl_algorithm = @rl.PPO
nlimb.NLIMB.design_dist = @nlimb.HexGrammarDesignDist
nlimb.NLIMB.steps_per_design = 3000
nlimb.NLIMB.learning_starts = 20480
nlimb.NLIMB.update_period = 4096
nlimb.NLIMB.n_updates = 1
nlimb.NLIMB.optimizer = @nlimb/optim.AdamW
nlimb.NLIMB.lr = 0.001
nlimb.NLIMB.n_epochs = 2
nlimb.NLIMB.batch_size = 2048
nlimb.NLIMB.clip_param = 0.2
nlimb.NLIMB.kl_target = 0.0126
nlimb.NLIMB.ent_coef = 0.02
nlimb.NLIMB.lr_fac = 1.25
nlimb.NLIMB.max_lr = 0.1
nlimb.NLIMB.max_grad_norm = 0.1

nlimb.HexGrammarDesignDist.model = @nlimb.DesignTransformer
nlimb.DesignTransformer.dmodel = 64

rl.PPO.policy_fn = @rl.basic_transformer_policy
rl.PPO.optimizer = @optim.AdamW
rl.PPO.lr = 0.0003
rl.PPO.batch_size = 8192
rl.PPO.batches_per_update = 2
rl.PPO.rollout_length = 128
rl.PPO.gamma = 0.99
rl.PPO.lambda_ = 0.95
rl.PPO.epochs_per_rollout = 4
rl.PPO.max_grad_norm = 1.0
rl.PPO.ent_coef = 0.0
rl.PPO.vf_coef = 3.7
rl.PPO.bounds_coef = 100.
rl.PPO.clip_param = 0.2
rl.PPO.use_clipped_value_loss = True
rl.PPO.reward_scale = 0.01
rl.PPO.kl_target = 0.04
rl.PPO.kl_decay_period = 100000000
rl.PPO.kl_decay_fac = 0.5
rl.PPO.max_lr = 0.001
rl.PPO.min_lr = 0.000001
rl.PPO.kl_lr_update_fac = 1.1
rl.PPO.norm_advantages = True
rl.PPO.norm_observations = True
rl.PPO.use_masked_obs_norm = True
rl.PPO.norm_values = True
rl.PPO.eval_num_episodes = 2048
rl.PPO.eval_max_episode_length = 1000
rl.PPO.num_recording_envs = 0
rl.PPO.record_viewer = True

rl.basic_transformer_policy.nlayers = 1
rl.basic_transformer_policy.dmodel = 256
rl.basic_transformer_policy.nheads = 4
rl.basic_transformer_policy.activation_fn = @nn.ELU
rl.basic_transformer_policy.pos_encoding = @networks.ConcatLearnedTreePositionalEncoding
rl.basic_transformer_policy.include_terrain = True
rl.basic_transformer_policy.num_terrain_heads = 1
rl.basic_transformer_policy.use_mup = True

tasks.MoveToTarget.termination_height = 0.08
tasks.MoveToTarget.timeout = 1000
tasks.SwitchingTarget.termination_height = 0.08
tasks.SwitchingTarget.timeout = 1000

networks.ConcatLearnedTreePositionalEncoding.dropout = 0.0
networks.LearnedPositionalEncoding.dropout = 0.0
networks.NoPositionalEncoding.dropout = 0.0

envs.IsaacMixedXMLEnv.task = @tasks.MoveToTarget
envs.IsaacMixedXMLEnv.num_envs = 2048
envs.IsaacMixedXMLEnv.device = 'cuda:0'
envs.IsaacMixedXMLEnv.create_eval_sensors = False
envs.IsaacMixedXMLEnv.homogeneous_envs = False
envs.IsaacMixedXMLEnv.spacing = [0., 0.025, 1.]
envs.IsaacMixedXMLEnv.num_per_row = 1
envs.IsaacMixedXMLEnv.asset_root = '/xmls'
envs.IsaacMixedXMLEnv.terrain = @terrain.RandomWallsTerrain


PhysXParams.max_depenetration_velocity = 10.0
PhysXParams.num_velocity_iterations = 4
PhysXParams.rest_offset = 0.0
PhysXParams.contact_collection = 0  # CC_NEVER
PhysXParams.default_buffer_size_multiplier = 5
PhysXParams.num_subscenes = 4


DiagGaussian.constant_log_std = True

optim.Adam.betas = (0.9, 0.999)
optim.Adam.eps = 1e-5

mup.MuAdam.betas = (0.9, 0.999)
mup.MuAdam.eps = 1e-5

optim.AdamW.betas = (0.9, 0.999)
optim.AdamW.weight_decay = 0.018
optim.AdamW.eps = 1e-5

mup.MuAdamW.betas = (0.9, 0.999)
mup.MuAdamW.weight_decay = 0.018
mup.MuAdamW.eps = 1e-5

Checkpointer.ckpt_period = 1000000

tasks.MoveToTarget.progress_weight = 3.8
tasks.MoveToTarget.actions_cost_scale = 0.035
tasks.MoveToTarget.energy_cost_scale = 0.01
tasks.MoveToTarget.joints_at_limit_cost_scale = 0.2
